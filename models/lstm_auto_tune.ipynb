{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b70bb05c",
      "metadata": {
        "id": "b70bb05c",
        "papermill": {
          "duration": 0.004099,
          "end_time": "2025-04-18T10:38:12.937202",
          "exception": false,
          "start_time": "2025-04-18T10:38:12.933103",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Thay đổi batch size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f111cc3",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-18T10:38:12.945258Z",
          "iopub.status.busy": "2025-04-18T10:38:12.944603Z",
          "iopub.status.idle": "2025-04-18T10:38:12.950852Z",
          "shell.execute_reply": "2025-04-18T10:38:12.950168Z"
        },
        "id": "5f111cc3",
        "papermill": {
          "duration": 0.011514,
          "end_time": "2025-04-18T10:38:12.952051",
          "exception": false,
          "start_time": "2025-04-18T10:38:12.940537",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Thay đổi batch_size, 64 - 128 - 256 - 512\n",
        "\n",
        "batch_size = 256"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02001f97",
      "metadata": {
        "id": "02001f97",
        "papermill": {
          "duration": 0.002998,
          "end_time": "2025-04-18T10:38:12.958306",
          "exception": false,
          "start_time": "2025-04-18T10:38:12.955308",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Chạy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e990277",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-18T10:38:12.965736Z",
          "iopub.status.busy": "2025-04-18T10:38:12.965062Z",
          "iopub.status.idle": "2025-04-18T10:38:24.583383Z",
          "shell.execute_reply": "2025-04-18T10:38:24.582633Z"
        },
        "id": "2e990277",
        "outputId": "68db1615-c7f1-4e1c-bf9f-95da3779a837",
        "papermill": {
          "duration": 11.62334,
          "end_time": "2025-04-18T10:38:24.584744",
          "exception": false,
          "start_time": "2025-04-18T10:38:12.961404",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\r\n",
            "From: https://drive.google.com/uc?id=115b2vVHryiPFOPYRumGBDIpx5dT_vH7R\r\n",
            "To: /kaggle/working/aws_rainfall_all.parquet\r\n",
            "100%|███████████████████████████████████████| 50.6M/50.6M [00:00<00:00, 152MB/s]\r\n"
          ]
        }
      ],
      "source": [
        "!pip install -q gdown\n",
        "!gdown 115b2vVHryiPFOPYRumGBDIpx5dT_vH7R"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d51f1b25",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2025-04-18T10:38:24.593281Z",
          "iopub.status.busy": "2025-04-18T10:38:24.592793Z",
          "iopub.status.idle": "2025-04-18T10:38:26.392448Z",
          "shell.execute_reply": "2025-04-18T10:38:26.391634Z"
        },
        "id": "d51f1b25",
        "papermill": {
          "duration": 1.805309,
          "end_time": "2025-04-18T10:38:26.393869",
          "exception": false,
          "start_time": "2025-04-18T10:38:24.588560",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import gc\n",
        "import numpy as np\n",
        "\n",
        "pd.set_option(\"mode.chained_assignment\", None)  # Disable caching\n",
        "pd.options.display.memory_usage = False  # Reduce memory prints\n",
        "gc.collect()\n",
        "\n",
        "df = pd.read_parquet(\"/kaggle/working/aws_rainfall_all.parquet\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5123bf9",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-18T10:38:26.402167Z",
          "iopub.status.busy": "2025-04-18T10:38:26.401835Z",
          "iopub.status.idle": "2025-04-18T10:38:27.806279Z",
          "shell.execute_reply": "2025-04-18T10:38:27.805679Z"
        },
        "id": "a5123bf9",
        "papermill": {
          "duration": 1.409934,
          "end_time": "2025-04-18T10:38:27.807566",
          "exception": false,
          "start_time": "2025-04-18T10:38:26.397632",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "def calculate_optimum_alpha(data):\n",
        "    X_max = np.max(data)\n",
        "    X_min = np.min(data)\n",
        "    X_mean = np.mean(data)\n",
        "    return ((X_max - X_min) - X_mean) / (X_max - X_min) if (X_max - X_min) != 0 else 0.5\n",
        "\n",
        "def exponential_smoothing(data, alpha = 0.2):\n",
        "    smoothed = np.zeros_like(data)\n",
        "    smoothed[0] = data[0]\n",
        "    for t in range(1, len(data)):\n",
        "        smoothed[t] = alpha * data[t] + (1 - alpha) * smoothed[t-1]\n",
        "    return smoothed\n",
        "\n",
        "corr_matrix = df.corr()\n",
        "\n",
        "threshold = 0.05\n",
        "\n",
        "high_corr_features = corr_matrix[\"aws_rainfall\"][abs(corr_matrix[\"aws_rainfall\"]) > threshold].index.tolist()\n",
        "\n",
        "high_corr_features = [i for i in high_corr_features if i not in [\"Datetime\", \"Row\", \"Col\"]]\n",
        "\n",
        "def extract_to_numpy(df, n_steps = 6):\n",
        "    feature_cols = high_corr_features\n",
        "    X = []\n",
        "    y = []\n",
        "    positions = []\n",
        "    for (row, col), group in tqdm(df.groupby([\"Row\", \"Col\"]), desc=\"Processing groups\", unit=\"group\"):\n",
        "        group = group.sort_values(\"Datetime\")\n",
        "        group_values = group[feature_cols].values\n",
        "        original_rainfall_values = group['aws_rainfall'].values\n",
        "        alpha = calculate_optimum_alpha(original_rainfall_values)\n",
        "        # alpha = 0.5\n",
        "        rainfall_values = exponential_smoothing(original_rainfall_values, alpha)\n",
        "        for i in range(n_steps, len(group_values)):\n",
        "            if(len(group_values) < n_steps):\n",
        "                break\n",
        "            X.append(group_values[i - n_steps:i])\n",
        "            y.append(rainfall_values[i])\n",
        "            positions.append((row, col, group.iloc[i][\"Datetime\"]))\n",
        "    return np.array(X), np.array(y), np.array(positions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "927b585b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-18T10:38:27.815769Z",
          "iopub.status.busy": "2025-04-18T10:38:27.815550Z",
          "iopub.status.idle": "2025-04-18T10:38:31.291392Z",
          "shell.execute_reply": "2025-04-18T10:38:31.290489Z"
        },
        "id": "927b585b",
        "papermill": {
          "duration": 3.481629,
          "end_time": "2025-04-18T10:38:31.293014",
          "exception": false,
          "start_time": "2025-04-18T10:38:27.811385",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "columns = [i for i in high_corr_features if i != \"aws_rainfall\"]\n",
        "df_feat = df[columns].replace([9999, np.inf, -np.inf], np.nan)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "df_feat_scaled = pd.DataFrame(scaler.fit_transform(df_feat), columns = columns)\n",
        "\n",
        "imputer = KNNImputer(n_neighbors = 5, weights = \"distance\")\n",
        "df_feat_imputed_scaled = pd.DataFrame(imputer.fit_transform(df_feat_scaled), columns = columns)\n",
        "\n",
        "df_feat_imputed = pd.DataFrame(scaler.inverse_transform(df_feat_imputed_scaled), columns = columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1d558ed",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-18T10:38:31.302928Z",
          "iopub.status.busy": "2025-04-18T10:38:31.302576Z",
          "iopub.status.idle": "2025-04-18T10:38:31.344039Z",
          "shell.execute_reply": "2025-04-18T10:38:31.343241Z"
        },
        "id": "f1d558ed",
        "papermill": {
          "duration": 0.047901,
          "end_time": "2025-04-18T10:38:31.345534",
          "exception": false,
          "start_time": "2025-04-18T10:38:31.297633",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "new_df = pd.concat([df[[\"Datetime\", \"Row\", \"Col\", \"aws_rainfall\"]], df_feat_imputed], axis=1)\n",
        "del df_feat, df_feat_scaled, df_feat_imputed_scaled, df_feat_imputed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17bdd91b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-18T10:38:31.354395Z",
          "iopub.status.busy": "2025-04-18T10:38:31.353698Z",
          "iopub.status.idle": "2025-04-18T10:38:31.358649Z",
          "shell.execute_reply": "2025-04-18T10:38:31.357964Z"
        },
        "id": "17bdd91b",
        "papermill": {
          "duration": 0.010026,
          "end_time": "2025-04-18T10:38:31.359670",
          "exception": false,
          "start_time": "2025-04-18T10:38:31.349644",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "def data_smoothing(df):\n",
        "    feature_cols = [col for col in df.columns if col not in [\"Row\", \"Col\", \"Datetime\", \"aws_rainfall\", \"smoothed_rainfall\"]]\n",
        "\n",
        "    for (row, col), group in tqdm(df.groupby([\"Row\", \"Col\"]), desc=\"Processing groups\", unit=\"group\"):\n",
        "        group = group.sort_values(\"Datetime\")\n",
        "        original_rainfall_values = group['aws_rainfall'].values\n",
        "        alpha = calculate_optimum_alpha(original_rainfall_values)\n",
        "        alpha = 0.5\n",
        "        rainfall_values = exponential_smoothing(original_rainfall_values, alpha)\n",
        "\n",
        "        # Update smoothed rainfall values back to the DataFrame\n",
        "        df.loc[group.index, 'smoothed_rainfall'] = rainfall_values\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39936452",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-18T10:38:31.367346Z",
          "iopub.status.busy": "2025-04-18T10:38:31.366876Z",
          "iopub.status.idle": "2025-04-18T10:38:36.006124Z",
          "shell.execute_reply": "2025-04-18T10:38:36.005321Z"
        },
        "id": "39936452",
        "outputId": "4366da77-e8b4-4639-b35d-9fbe0916f3bc",
        "papermill": {
          "duration": 4.644269,
          "end_time": "2025-04-18T10:38:36.007322",
          "exception": false,
          "start_time": "2025-04-18T10:38:31.363053",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing groups: 100%|██████████| 334/334 [00:03<00:00, 86.92group/s]\n"
          ]
        }
      ],
      "source": [
        "new_df = data_smoothing(new_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7357cd11",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-18T10:38:36.017847Z",
          "iopub.status.busy": "2025-04-18T10:38:36.017627Z",
          "iopub.status.idle": "2025-04-18T10:39:37.718102Z",
          "shell.execute_reply": "2025-04-18T10:39:37.717505Z"
        },
        "id": "7357cd11",
        "outputId": "3299702a-9401-4d38-aec7-b9cc99d4b02a",
        "papermill": {
          "duration": 61.707258,
          "end_time": "2025-04-18T10:39:37.719551",
          "exception": false,
          "start_time": "2025-04-18T10:38:36.012293",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processing groups: 100%|██████████| 334/334 [00:58<00:00,  5.68group/s]\n"
          ]
        }
      ],
      "source": [
        "x, y, z = extract_to_numpy(new_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61a70ddd",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-18T10:39:37.756446Z",
          "iopub.status.busy": "2025-04-18T10:39:37.756211Z",
          "iopub.status.idle": "2025-04-18T10:39:37.760485Z",
          "shell.execute_reply": "2025-04-18T10:39:37.759712Z"
        },
        "id": "61a70ddd",
        "outputId": "84a46c0a-7a53-4321-a154-b54ada768d10",
        "papermill": {
          "duration": 0.023168,
          "end_time": "2025-04-18T10:39:37.761627",
          "exception": false,
          "start_time": "2025-04-18T10:39:37.738459",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of X: (935534, 6, 13)\n",
            "Shape of y: (935534,)\n",
            "Shape of positions: (935534, 3)\n"
          ]
        }
      ],
      "source": [
        "print(\"Shape of X:\", x.shape)\n",
        "print(\"Shape of y:\", y.shape)\n",
        "print(\"Shape of positions:\", z.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af07c723",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-18T10:39:37.796435Z",
          "iopub.status.busy": "2025-04-18T10:39:37.796232Z",
          "iopub.status.idle": "2025-04-18T10:39:39.886030Z",
          "shell.execute_reply": "2025-04-18T10:39:39.885428Z"
        },
        "id": "af07c723",
        "papermill": {
          "duration": 2.108929,
          "end_time": "2025-04-18T10:39:39.887550",
          "exception": false,
          "start_time": "2025-04-18T10:39:37.778621",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "\n",
        "# Initialize scalers\n",
        "rainfall_scaler = MinMaxScaler()  # For past rainfall (first feature) & y\n",
        "features_scaler = MinMaxScaler()  # For other features\n",
        "\n",
        "# Fit rainfall scaler on both past rainfall and y\n",
        "rainfall_scaler.fit(np.concatenate([y.reshape(-1, 1), x[:, :, 0].reshape(-1, 1)]))\n",
        "\n",
        "# Transform y\n",
        "y_scaled = rainfall_scaler.transform(y.reshape(-1, 1)).flatten()\n",
        "\n",
        "# Copy x to avoid modifying original data\n",
        "x_scaled = np.copy(x)\n",
        "\n",
        "# Scale only the first feature (past rainfall) using rainfall_scaler\n",
        "x_scaled[:, :, 0] = rainfall_scaler.transform(x[:, :, 0].reshape(-1, 1)).reshape(x.shape[0], x.shape[1])\n",
        "\n",
        "# Get the actual number of features dynamically\n",
        "num_features = x.shape[2] - 1  # Exclude the first feature\n",
        "\n",
        "# Scale the remaining features\n",
        "x_scaled[:, :, 1:] = features_scaler.fit_transform(x[:, :, 1:].reshape(-1, num_features)).reshape(x.shape[0], x.shape[1], num_features)\n",
        "\n",
        "# Function to inverse transform y predictions\n",
        "def inverse_transform_y(y_pred_scaled):\n",
        "    return rainfall_scaler.inverse_transform(y_pred_scaled.reshape(-1, 1)).flatten()\n",
        "\n",
        "# Train-test split\n",
        "# X_train, X_test, y_train, y_test, z_train, z_test = train_test_split(x_scaled, y_scaled, z, test_size=0.2, random_state=42)\n",
        "\n",
        "split_index = int(len(x_scaled) * 0.8)  \n",
        "\n",
        "# Training set (first 80%)\n",
        "X_train, y_train, z_train = x_scaled[:split_index], y_scaled[:split_index], z[:split_index]\n",
        "\n",
        "# Testing set (last 20%)\n",
        "X_test, y_test, z_test = x_scaled[split_index:], y_scaled[split_index:], z[split_index:]\n",
        "\n",
        "# Reshape z_train and z_test\n",
        "z_train = z_train.reshape(-1, 3)\n",
        "z_test = z_test.reshape(-1, 3)\n",
        "\n",
        "# Ensure y_train and y_test remain 1D\n",
        "y_train = y_train.flatten()\n",
        "y_test = y_test.flatten()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48bc0a21",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-18T10:39:39.923414Z",
          "iopub.status.busy": "2025-04-18T10:39:39.923026Z",
          "iopub.status.idle": "2025-04-18T14:54:13.231422Z",
          "shell.execute_reply": "2025-04-18T14:54:13.230691Z"
        },
        "id": "48bc0a21",
        "outputId": "9ae4345a-cac3-4a24-feea-d54b830c887e",
        "papermill": {
          "duration": 15273.33,
          "end_time": "2025-04-18T14:54:13.235029",
          "exception": false,
          "start_time": "2025-04-18T10:39:39.905029",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 90 Complete [00h 10m 33s]\n",
            "val_loss: 0.0001391547848470509\n",
            "\n",
            "Best val_loss So Far: 0.00013905524974688888\n",
            "Total elapsed time: 04h 14m 19s\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import LSTM, Dropout, Dense, BatchNormalization, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import keras_tuner as kt\n",
        "\n",
        "n_steps, num_features = x.shape[1], x.shape[2]\n",
        "\n",
        "def build_model(hp):\n",
        "    # Hyperparameters\n",
        "    lstm_units_1 = hp.Int('lstm_units_1', min_value=32, max_value=256, step=32)\n",
        "    lstm_units_2 = hp.Int('lstm_units_2', min_value=16, max_value=128, step=16)\n",
        "    lstm_units_3 = hp.Int('lstm_units_3', min_value=8, max_value=64, step=8)\n",
        "\n",
        "    dropout_rate_1 = hp.Float('dropout_rate_1', min_value=0.0, max_value=0.5, step=0.1)\n",
        "    dropout_rate_2 = hp.Float('dropout_rate_2', min_value=0.0, max_value=0.5, step=0.1)\n",
        "    dropout_rate_3 = hp.Float('dropout_rate_3', min_value=0.0, max_value=0.5, step=0.1)\n",
        "\n",
        "    learning_rate = hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='log')\n",
        "\n",
        "    # Create model using Functional API\n",
        "    inputs = Input(shape=(n_steps, num_features))\n",
        "\n",
        "    # First LSTM layer\n",
        "    lstm1 = LSTM(lstm_units_1, activation='relu', return_sequences=True)(inputs)\n",
        "    bn1 = BatchNormalization()(lstm1)\n",
        "    drop1 = Dropout(dropout_rate_1)(bn1)\n",
        "\n",
        "    # Second LSTM layer\n",
        "    lstm2 = LSTM(lstm_units_2, activation='relu', return_sequences=True)(drop1)\n",
        "    bn2 = BatchNormalization()(lstm2)\n",
        "    drop2 = Dropout(dropout_rate_2)(bn2)\n",
        "\n",
        "    # Third LSTM layer\n",
        "    lstm3 = LSTM(lstm_units_3, activation='relu')(drop2)\n",
        "    bn3 = BatchNormalization()(lstm3)\n",
        "    drop3 = Dropout(dropout_rate_3)(bn3)\n",
        "\n",
        "    # Output layer\n",
        "    outputs = Dense(1, activation='linear')(drop3)\n",
        "\n",
        "    # Create model\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    # Compile the model\n",
        "    optimizer = Adam(learning_rate=learning_rate)\n",
        "    model.compile(optimizer=optimizer, loss='mse', metrics=['mae'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Set up the Keras Tuner\n",
        "tuner = kt.Hyperband(\n",
        "    build_model,\n",
        "    objective='val_loss',\n",
        "    max_epochs=64,\n",
        "    factor=3,\n",
        "    directory='keras_tuner_dir',\n",
        "    project_name='lstm_tuning'\n",
        ")\n",
        "\n",
        "tuner.search_space_summary()\n",
        "\n",
        "# Early stopping callback\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=15,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "# Start the hyperparameter search\n",
        "tuner.search(\n",
        "    X_train, y_train,\n",
        "    epochs=100,\n",
        "    validation_data=(X_test, y_test),\n",
        "    callbacks=[early_stopping],\n",
        "    batch_size=batch_size\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9016ffb",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-18T14:54:13.272065Z",
          "iopub.status.busy": "2025-04-18T14:54:13.271398Z",
          "iopub.status.idle": "2025-04-18T15:04:05.786381Z",
          "shell.execute_reply": "2025-04-18T15:04:05.785575Z"
        },
        "id": "e9016ffb",
        "outputId": "ada0ae8b-aea5-442a-b391-50763ec98b75",
        "papermill": {
          "duration": 592.533732,
          "end_time": "2025-04-18T15:04:05.787456",
          "exception": false,
          "start_time": "2025-04-18T14:54:13.253724",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best LSTM units 1: 32\n",
            "Best LSTM units 2: 80\n",
            "Best LSTM units 3: 32\n",
            "Best dropout rate 1: 0.2\n",
            "Best dropout rate 2: 0.0\n",
            "Best dropout rate 3: 0.4\n",
            "Best learning rate: 0.0003424899128529849\n",
            "Epoch 1/64\n",
            "\u001b[1m2924/2924\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 6ms/step - loss: 0.6097 - mae: 0.4815 - val_loss: 2.5004e-04 - val_mae: 0.0041\n",
            "Epoch 2/64\n",
            "\u001b[1m2924/2924\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - loss: 3.7225e-04 - mae: 0.0082 - val_loss: 2.4137e-04 - val_mae: 0.0032\n",
            "Epoch 3/64\n",
            "\u001b[1m2924/2924\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - loss: 2.2756e-04 - mae: 0.0038 - val_loss: 2.2435e-04 - val_mae: 0.0030\n",
            "Epoch 4/64\n",
            "\u001b[1m2924/2924\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - loss: 2.0767e-04 - mae: 0.0038 - val_loss: 1.9824e-04 - val_mae: 0.0027\n",
            "Epoch 5/64\n",
            "\u001b[1m2924/2924\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - loss: 2.0101e-04 - mae: 0.0037 - val_loss: 1.7821e-04 - val_mae: 0.0025\n",
            "Epoch 6/64\n",
            "\u001b[1m2924/2924\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - loss: 1.8222e-04 - mae: 0.0036 - val_loss: 3.0761e-04 - val_mae: 0.0026\n",
            "Epoch 7/64\n",
            "\u001b[1m2924/2924\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - loss: 1.7530e-04 - mae: 0.0035 - val_loss: 1.7224e-04 - val_mae: 0.0029\n",
            "Epoch 8/64\n",
            "\u001b[1m2924/2924\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - loss: 1.6447e-04 - mae: 0.0032 - val_loss: 1.4833e-04 - val_mae: 0.0025\n",
            "Epoch 9/64\n",
            "\u001b[1m2924/2924\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - loss: 1.6135e-04 - mae: 0.0031 - val_loss: 1.7667e-04 - val_mae: 0.0024\n",
            "Epoch 10/64\n",
            "\u001b[1m2924/2924\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - loss: 1.5535e-04 - mae: 0.0029 - val_loss: 1.4404e-04 - val_mae: 0.0020\n",
            "Epoch 11/64\n",
            "\u001b[1m2924/2924\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - loss: 1.4654e-04 - mae: 0.0027 - val_loss: 1.5305e-04 - val_mae: 0.0040\n",
            "Epoch 12/64\n",
            "\u001b[1m2924/2924\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - loss: 1.4994e-04 - mae: 0.0026 - val_loss: 1.4932e-04 - val_mae: 0.0019\n",
            "Epoch 13/64\n",
            "\u001b[1m2924/2924\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - loss: 1.3698e-04 - mae: 0.0026 - val_loss: 1.5096e-04 - val_mae: 0.0034\n",
            "Epoch 14/64\n",
            "\u001b[1m2924/2924\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - loss: 1.4153e-04 - mae: 0.0027 - val_loss: 1.4604e-04 - val_mae: 0.0027\n",
            "Epoch 15/64\n",
            "\u001b[1m2924/2924\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - loss: 1.4252e-04 - mae: 0.0026 - val_loss: 1.4312e-04 - val_mae: 0.0030\n",
            "Epoch 16/64\n",
            "\u001b[1m2924/2924\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - loss: 1.4030e-04 - mae: 0.0026 - val_loss: 1.4449e-04 - val_mae: 0.0033\n",
            "Epoch 17/64\n",
            "\u001b[1m2924/2924\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - loss: 1.3618e-04 - mae: 0.0025 - val_loss: 1.4760e-04 - val_mae: 0.0022\n",
            "Epoch 18/64\n",
            "\u001b[1m2924/2924\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - loss: 1.2786e-04 - mae: 0.0025 - val_loss: 1.4013e-04 - val_mae: 0.0024\n",
            "Epoch 19/64\n",
            "\u001b[1m2924/2924\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - loss: 1.3860e-04 - mae: 0.0025 - val_loss: 1.4950e-04 - val_mae: 0.0025\n",
            "Epoch 20/64\n",
            "\u001b[1m2924/2924\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - loss: 1.3955e-04 - mae: 0.0025 - val_loss: 1.4178e-04 - val_mae: 0.0028\n",
            "Epoch 21/64\n",
            "\u001b[1m2924/2924\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - loss: 1.3664e-04 - mae: 0.0025 - val_loss: 1.4332e-04 - val_mae: 0.0026\n",
            "Epoch 22/64\n",
            "\u001b[1m2924/2924\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - loss: 1.4143e-04 - mae: 0.0025 - val_loss: 1.4246e-04 - val_mae: 0.0023\n",
            "Epoch 23/64\n",
            "\u001b[1m2924/2924\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - loss: 1.3625e-04 - mae: 0.0025 - val_loss: 1.4166e-04 - val_mae: 0.0026\n",
            "Epoch 24/64\n",
            "\u001b[1m2924/2924\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - loss: 1.4159e-04 - mae: 0.0025 - val_loss: 1.4525e-04 - val_mae: 0.0020\n",
            "Epoch 25/64\n",
            "\u001b[1m2924/2924\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - loss: 1.3835e-04 - mae: 0.0025 - val_loss: 1.4206e-04 - val_mae: 0.0018\n",
            "Epoch 26/64\n",
            "\u001b[1m2924/2924\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - loss: 1.3148e-04 - mae: 0.0025 - val_loss: 1.5054e-04 - val_mae: 0.0041\n",
            "Epoch 27/64\n",
            "\u001b[1m2924/2924\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - loss: 1.4184e-04 - mae: 0.0025 - val_loss: 1.3992e-04 - val_mae: 0.0018\n",
            "Epoch 28/64\n",
            "\u001b[1m2924/2924\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - loss: 1.4184e-04 - mae: 0.0025 - val_loss: 1.4418e-04 - val_mae: 0.0021\n",
            "Epoch 29/64\n",
            "\u001b[1m2924/2924\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - loss: 1.3137e-04 - mae: 0.0025 - val_loss: 1.4114e-04 - val_mae: 0.0019\n",
            "Epoch 30/64\n",
            "\u001b[1m2924/2924\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - loss: 1.3634e-04 - mae: 0.0025 - val_loss: 1.4797e-04 - val_mae: 0.0019\n",
            "Epoch 31/64\n",
            "\u001b[1m2924/2924\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - loss: 1.3592e-04 - mae: 0.0025 - val_loss: 1.4570e-04 - val_mae: 0.0025\n",
            "Epoch 32/64\n",
            "\u001b[1m2924/2924\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - loss: 1.2915e-04 - mae: 0.0025 - val_loss: 1.4030e-04 - val_mae: 0.0020\n",
            "Epoch 33/64\n",
            "\u001b[1m2924/2924\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - loss: 1.2838e-04 - mae: 0.0025 - val_loss: 1.3974e-04 - val_mae: 0.0023\n",
            "Epoch 34/64\n",
            "\u001b[1m2924/2924\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - loss: 1.3157e-04 - mae: 0.0025 - val_loss: 1.4208e-04 - val_mae: 0.0019\n",
            "Epoch 35/64\n",
            "\u001b[1m2924/2924\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - loss: 1.4108e-04 - mae: 0.0025 - val_loss: 1.4064e-04 - val_mae: 0.0026\n",
            "Epoch 36/64\n",
            "\u001b[1m2924/2924\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - loss: 1.3999e-04 - mae: 0.0025 - val_loss: 1.4483e-04 - val_mae: 0.0025\n",
            "Epoch 37/64\n",
            "\u001b[1m2924/2924\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - loss: 1.3732e-04 - mae: 0.0025 - val_loss: 1.4651e-04 - val_mae: 0.0025\n",
            "Epoch 38/64\n",
            "\u001b[1m2924/2924\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - loss: 1.3713e-04 - mae: 0.0025 - val_loss: 1.6270e-04 - val_mae: 0.0018\n",
            "Epoch 39/64\n",
            "\u001b[1m2924/2924\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - loss: 1.2508e-04 - mae: 0.0024 - val_loss: 1.4937e-04 - val_mae: 0.0041\n",
            "Epoch 40/64\n",
            "\u001b[1m2924/2924\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - loss: 1.2830e-04 - mae: 0.0025 - val_loss: 1.4154e-04 - val_mae: 0.0023\n",
            "Epoch 41/64\n",
            "\u001b[1m2924/2924\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - loss: 1.3173e-04 - mae: 0.0025 - val_loss: 1.4126e-04 - val_mae: 0.0020\n",
            "Epoch 42/64\n",
            "\u001b[1m2924/2924\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - loss: 1.3501e-04 - mae: 0.0025 - val_loss: 1.5792e-04 - val_mae: 0.0019\n",
            "Epoch 43/64\n",
            "\u001b[1m2924/2924\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - loss: 1.2692e-04 - mae: 0.0024 - val_loss: 1.4703e-04 - val_mae: 0.0037\n",
            "Epoch 44/64\n",
            "\u001b[1m2924/2924\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - loss: 1.3721e-04 - mae: 0.0025 - val_loss: 1.5461e-04 - val_mae: 0.0019\n",
            "Epoch 45/64\n",
            "\u001b[1m2924/2924\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - loss: 1.2948e-04 - mae: 0.0024 - val_loss: 1.4223e-04 - val_mae: 0.0029\n",
            "Epoch 46/64\n",
            "\u001b[1m2924/2924\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - loss: 1.3383e-04 - mae: 0.0025 - val_loss: 1.4765e-04 - val_mae: 0.0020\n",
            "Epoch 47/64\n",
            "\u001b[1m2924/2924\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - loss: 1.2759e-04 - mae: 0.0025 - val_loss: 1.4934e-04 - val_mae: 0.0020\n",
            "Epoch 48/64\n",
            "\u001b[1m2924/2924\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - loss: 1.3287e-04 - mae: 0.0025 - val_loss: 1.4302e-04 - val_mae: 0.0023\n",
            "\u001b[1m5848/5848\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - loss: 1.1665e-04 - mae: 0.0022\n",
            "Test loss: [0.00013973948080092669, 0.0022850665263831615]\n"
          ]
        }
      ],
      "source": [
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "print(f\"Best LSTM units 1: {best_hps.get('lstm_units_1')}\")\n",
        "print(f\"Best LSTM units 2: {best_hps.get('lstm_units_2')}\")\n",
        "print(f\"Best LSTM units 3: {best_hps.get('lstm_units_3')}\")\n",
        "print(f\"Best dropout rate 1: {best_hps.get('dropout_rate_1')}\")\n",
        "print(f\"Best dropout rate 2: {best_hps.get('dropout_rate_2')}\")\n",
        "print(f\"Best dropout rate 3: {best_hps.get('dropout_rate_3')}\")\n",
        "print(f\"Best learning rate: {best_hps.get('learning_rate')}\")\n",
        "\n",
        "model = tuner.hypermodel.build(best_hps)\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=64,\n",
        "    batch_size=batch_size,\n",
        "    validation_data=(X_test, y_test),\n",
        "    callbacks=[early_stopping]\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss = model.evaluate(X_test, y_test)\n",
        "print(f\"Test loss: {test_loss}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f36e920",
      "metadata": {
        "id": "0f36e920",
        "papermill": {
          "duration": 0.422043,
          "end_time": "2025-04-18T15:04:06.631927",
          "exception": false,
          "start_time": "2025-04-18T15:04:06.209884",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25f749d8",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-18T15:04:07.576222Z",
          "iopub.status.busy": "2025-04-18T15:04:07.575921Z",
          "iopub.status.idle": "2025-04-18T15:04:21.823545Z",
          "shell.execute_reply": "2025-04-18T15:04:21.822660Z"
        },
        "id": "25f749d8",
        "outputId": "1b8bad73-4e43-4f5b-d1d9-5f71646326a8",
        "papermill": {
          "duration": 14.767282,
          "end_time": "2025-04-18T15:04:21.824721",
          "exception": false,
          "start_time": "2025-04-18T15:04:07.057439",
          "status": "completed"
        },
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m5848/5848\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step\n",
            "MAE: 0.0023\n",
            "MSE: 0.0001\n",
            "RMSE: 0.0118\n",
            "R² Score: 0.4609\n"
          ]
        }
      ],
      "source": [
        "y_pred = model.predict(X_test)\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"MAE: {mae:.4f}\")\n",
        "print(f\"MSE: {mse:.4f}\")\n",
        "print(f\"RMSE: {rmse:.4f}\")\n",
        "print(f\"R² Score: {r2:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "79939594",
      "metadata": {
        "id": "79939594",
        "papermill": {
          "duration": 0.432753,
          "end_time": "2025-04-18T15:04:25.572437",
          "exception": false,
          "start_time": "2025-04-18T15:04:25.139684",
          "status": "completed"
        },
        "tags": []
      },
      "source": [
        "## So sánh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ca1be46",
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(y_test, label=\"Actual\")\n",
        "plt.plot(y_pred, label=\"Predicted\", linestyle=\"dashed\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "datasetId": 6891645,
          "sourceId": 11060838,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 31011,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 15996.224968,
      "end_time": "2025-04-18T15:04:45.033975",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2025-04-18T10:38:08.809007",
      "version": "2.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
